# local-chat-gpt

## 起動方法

1. 起動

``` bash
docker-compose up -d
docker compose exec ollama ollama pull gpt-oss:20b
```

2. WebUIへアクセス

`localhost:3000`にアクセスする


## デモ

[【Ollama】ローカル環境で大規模言語モデルを実行可能なOllamaをインストールしてみた - YouTube](https://www.youtube.com/watch?v=ZD7tdA8tKhk)